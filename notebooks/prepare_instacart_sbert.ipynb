{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Instacart data preparation for two-tower SBERT\n",
        "\n",
        "This notebook mirrors `src/data/prepare_instacart_sbert.py`: same functions, compact context format (`[+Nd w{dow}h{hour}]`, `Next: +{gap}d w{dow}h{hour}`), and script defaults. Uses a small subset by default (`max_target_orders=500`) for fast iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: paths and config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA_DIR: /Users/chen_bowen/AI & ML/Projects/Instacart_Personalization/data\n",
            "OUTPUT_DIR: /Users/chen_bowen/AI & ML/Projects/Instacart_Personalization/processed\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "from src.constants import DEFAULT_DATA_DIR, DEFAULT_PROCESSED_DIR\n",
        "\n",
        "DATA_DIR = DEFAULT_DATA_DIR\n",
        "OUTPUT_DIR = DEFAULT_PROCESSED_DIR\n",
        "CHUNK_SIZE = 500_000  # for reading order_products__prior.csv (matches script)\n",
        "\n",
        "# Config: script defaults are max_prior_orders=5, max_product_names=20\n",
        "MAX_TARGET_ORDERS = 500  # limit target orders for fast iteration (script: --max-target-orders)\n",
        "MAX_PRIOR_ORDERS = 5\n",
        "MAX_PRODUCT_NAMES = 20\n",
        "EVAL_FRAC = 0.1\n",
        "EVAL_SERVE_TIME = True  # strip \" Next: ...\" from eval queries so eval matches production\n",
        "SAMPLE_FRAC = None\n",
        "SEED = 42\n",
        "\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"OUTPUT_DIR:\", OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. `load_product_text_map`\n",
        "\n",
        "Builds `product_id -> \"Product: {name}. Aisle: {aisle}. Department: {department}.\"`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_product_text_map(\n",
        "    products_path: Path, aisles_path: Path, departments_path: Path\n",
        ") -> dict[int, str]:\n",
        "    \"\"\"\n",
        "    Build a mapping from product_id to a single text string for the item tower.\n",
        "\n",
        "    Joins products with aisle and department names, then formats each product as\n",
        "    \"Product: {name}. Aisle: {aisle}. Department: {department}.\" for use as\n",
        "    the \"positive\" (item) side of (anchor, positive) pairs.\n",
        "    \"\"\"\n",
        "    products = pd.read_csv(products_path)\n",
        "    aisles = pd.read_csv(aisles_path)\n",
        "    departments = pd.read_csv(departments_path)\n",
        "    products = products.merge(aisles, on=\"aisle_id\").merge(\n",
        "        departments, on=\"department_id\"\n",
        "    )\n",
        "    products[\"text\"] = (\n",
        "        \"Product: \"\n",
        "        + products[\"product_name\"].astype(str)\n",
        "        + \". Aisle: \"\n",
        "        + products[\"aisle\"].astype(str)\n",
        "        + \". Department: \"\n",
        "        + products[\"department\"].astype(str)\n",
        "        + \".\"\n",
        "    )\n",
        "    return dict(zip(products[\"product_id\"], products[\"text\"]))\n",
        "\n",
        "product_text_map = load_product_text_map(\n",
        "    DATA_DIR / \"products.csv\",\n",
        "    DATA_DIR / \"aisles.csv\",\n",
        "    DATA_DIR / \"departments.csv\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Len: 49688\n",
            "\n",
            "Sample (first 5 product_ids):\n",
            "  1: Product: Chocolate Sandwich Cookies. Aisle: cookies cakes. Department: snacks....\n",
            "  2: Product: All-Seasons Salt. Aisle: spices seasonings. Department: pantry....\n",
            "  3: Product: Robust Golden Unsweetened Oolong Tea. Aisle: tea. Department: beverages...\n",
            "  4: Product: Smart Ones Classic Favorites Mini Rigatoni With Vodka Cream Sauce. Aisl...\n",
            "  5: Product: Green Chile Anytime Sauce. Aisle: marinades meat preparation. Departmen...\n"
          ]
        }
      ],
      "source": [
        "# Inspect output\n",
        "print(\"Len:\", len(product_text_map))\n",
        "print(\"\\nSample (first 5 product_ids):\")\n",
        "for pid, text in list(product_text_map.items())[:5]:\n",
        "    print(f\"  {pid}: {text[:80]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. `load_orders`\n",
        "\n",
        "Returns `(target_orders, history_orders)` DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_orders(orders_path: Path) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Load orders.csv and split into train vs prior by eval_set.\n",
        "\n",
        "    Target orders are the \"next\" order we predict for each user; history orders\n",
        "    are that user's history used only to build context (no leakage).\n",
        "    \"\"\"\n",
        "    orders = pd.read_csv(orders_path)\n",
        "    if orders[\"order_hour_of_day\"].dtype == object:\n",
        "        orders[\"order_hour_of_day\"] = (\n",
        "            orders[\"order_hour_of_day\"].astype(str).str.zfill(2)\n",
        "        )\n",
        "    target_orders = orders[orders[\"eval_set\"] == \"train\"][\n",
        "        [\n",
        "            \"order_id\",\n",
        "            \"user_id\",\n",
        "            \"order_number\",\n",
        "            \"order_dow\",\n",
        "            \"order_hour_of_day\",\n",
        "            \"days_since_prior_order\",\n",
        "        ]\n",
        "    ].copy()\n",
        "    history_orders = orders[orders[\"eval_set\"] == \"prior\"][\n",
        "        [\n",
        "            \"order_id\",\n",
        "            \"user_id\",\n",
        "            \"order_number\",\n",
        "            \"order_dow\",\n",
        "            \"order_hour_of_day\",\n",
        "            \"days_since_prior_order\",\n",
        "        ]\n",
        "    ].copy()\n",
        "    return target_orders, history_orders\n",
        "\n",
        "target_orders_full, history_orders_full = load_orders(DATA_DIR / \"orders.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target_orders shape: (131209, 6)\n",
            "history_orders shape: (3214874, 6)\n",
            "\n",
            "target_orders head:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>order_number</th>\n",
              "      <th>order_dow</th>\n",
              "      <th>order_hour_of_day</th>\n",
              "      <th>days_since_prior_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1187899</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1492625</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2196797</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>525192</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>880375</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>1094988</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>1822501</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>1827621</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>2316178</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>2180313</td>\n",
              "      <td>17</td>\n",
              "      <td>41</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     order_id  user_id  order_number  order_dow  order_hour_of_day  \\\n",
              "10    1187899        1            11          4                  8   \n",
              "25    1492625        2            15          1                 11   \n",
              "49    2196797        5             5          0                 11   \n",
              "74     525192        7            21          2                 11   \n",
              "78     880375        8             4          1                 14   \n",
              "82    1094988        9             4          6                 10   \n",
              "88    1822501       10             6          0                 19   \n",
              "115   1827621       13            13          0                 21   \n",
              "129   2316178       14            14          2                 19   \n",
              "200   2180313       17            41          3                 10   \n",
              "\n",
              "     days_since_prior_order  \n",
              "10                     14.0  \n",
              "25                     30.0  \n",
              "49                      6.0  \n",
              "74                      6.0  \n",
              "78                     10.0  \n",
              "82                     30.0  \n",
              "88                     30.0  \n",
              "115                     8.0  \n",
              "129                    11.0  \n",
              "200                    30.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "history_orders head:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>order_number</th>\n",
              "      <th>order_dow</th>\n",
              "      <th>order_hour_of_day</th>\n",
              "      <th>days_since_prior_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2539329</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2398795</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>473747</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2254736</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>431534</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3367565</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>550135</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3108588</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2295261</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2550362</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   order_id  user_id  order_number  order_dow  order_hour_of_day  \\\n",
              "0   2539329        1             1          2                  8   \n",
              "1   2398795        1             2          3                  7   \n",
              "2    473747        1             3          3                 12   \n",
              "3   2254736        1             4          4                  7   \n",
              "4    431534        1             5          4                 15   \n",
              "5   3367565        1             6          2                  7   \n",
              "6    550135        1             7          1                  9   \n",
              "7   3108588        1             8          1                 14   \n",
              "8   2295261        1             9          1                 16   \n",
              "9   2550362        1            10          4                  8   \n",
              "\n",
              "   days_since_prior_order  \n",
              "0                     NaN  \n",
              "1                    15.0  \n",
              "2                    21.0  \n",
              "3                    29.0  \n",
              "4                    28.0  \n",
              "5                    19.0  \n",
              "6                    20.0  \n",
              "7                    14.0  \n",
              "8                     0.0  \n",
              "9                    30.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"target_orders shape:\", target_orders_full.shape)\n",
        "print(\"history_orders shape:\", history_orders_full.shape)\n",
        "print(\"\\ntarget_orders head:\")\n",
        "display(target_orders_full.head(10))\n",
        "print(\"\\nhistory_orders head:\")\n",
        "display(history_orders_full.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After limiting: target_orders 500 , history_orders 7663 , history_order_ids 7663\n"
          ]
        }
      ],
      "source": [
        "# Limit to subset for fast iteration (script: --max-target-orders)\n",
        "target_orders = target_orders_full.head(MAX_TARGET_ORDERS)\n",
        "users_needed = set(target_orders[\"user_id\"].tolist())\n",
        "history_orders = history_orders_full[history_orders_full[\"user_id\"].isin(users_needed)]\n",
        "history_order_ids = set(history_orders[\"order_id\"].tolist())\n",
        "\n",
        "print(\"After limiting: target_orders\", target_orders.shape[0], \", history_orders\", history_orders.shape[0], \", history_order_ids\", len(history_order_ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. `build_order_to_products`\n",
        "\n",
        "Builds `order_id -> list of product_id` for prior orders (chunked read)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_order_to_products(\n",
        "    order_products_prior_path: Path,\n",
        "    history_order_ids: set[int],\n",
        "    chunk_size: int = CHUNK_SIZE,\n",
        ") -> dict[int, list[int]]:\n",
        "    \"\"\"\n",
        "    Build a mapping from each history order_id to the list of product_ids in that order.\n",
        "\n",
        "    Reads order_products__prior.csv in chunks. Only rows whose order_id is in\n",
        "    history_order_ids are kept.\n",
        "    \"\"\"\n",
        "    order_to_products = defaultdict(list)\n",
        "    for chunk in pd.read_csv(order_products_prior_path, chunksize=chunk_size):\n",
        "        chunk = chunk[chunk[\"order_id\"].isin(history_order_ids)]\n",
        "        for order_id, product_id in chunk[[\"order_id\", \"product_id\"]].itertuples(\n",
        "            index=False\n",
        "        ):\n",
        "            order_to_products[order_id].append(product_id)\n",
        "    return dict(order_to_products)\n",
        "\n",
        "order_to_products = build_order_to_products(\n",
        "    DATA_DIR / \"order_products__prior.csv\", history_order_ids\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num orders with products: 7663\n",
            "Products per order: min 1 , max 89 , mean 9.778285266866762\n",
            "\n",
            "Sample (first 3 order_id -> product_ids):\n",
            "  order_id 40: 4 products, first 5 ids: [10070, 42450, 33198, 34866]\n",
            "  order_id 1483: 12 products, first 5 ids: [32818, 27582, 12302, 1831, 19204]\n",
            "  order_id 2199: 15 products, first 5 ids: [24852, 17616, 47877, 33313, 651]\n"
          ]
        }
      ],
      "source": [
        "print(\"Num orders with products:\", len(order_to_products))\n",
        "lens = [len(v) for v in order_to_products.values()]\n",
        "print(\"Products per order: min\", min(lens), \", max\", max(lens), \", mean\", sum(lens)/len(lens))\n",
        "print(\"\\nSample (first 3 order_id -> product_ids):\")\n",
        "for oid, pids in list(order_to_products.items())[:3]:\n",
        "    print(f\"  order_id {oid}: {len(pids)} products, first 5 ids: {pids[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. `build_user_context_for_target_orders`\n",
        "\n",
        "For each target order, build user context string from order history only. Uses compact format: `[+Nd w{dow}h{hour}]` and `Next: +{gap}d w{dow}h{hour}` (script default)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_user_context_for_target_orders(\n",
        "    target_orders: pd.DataFrame,\n",
        "    history_orders: pd.DataFrame,\n",
        "    order_to_products: dict[int, list[int]],\n",
        "    product_text_map: dict[int, str],\n",
        "    max_prior_orders: int = 5,\n",
        "    max_product_names: int = 20,\n",
        ") -> dict[int, str]:\n",
        "    \"\"\"\n",
        "    For each target order, build one user-context string using only that user's order history.\n",
        "\n",
        "    Context format (compact): \"[w{dow}h{hour}] name1, name2; [+{days}d w{dow}h{hour}] ... Next: +{gap}d w{dow}h{hour}\"\n",
        "    Used as the \"anchor\" (query) side in (anchor, positive) pairs. No leakage.\n",
        "    \"\"\"\n",
        "    history_orders = history_orders.sort_values([\"user_id\", \"order_number\"])\n",
        "    order_id_to_context: dict[int, str] = {}\n",
        "\n",
        "    for _, row in target_orders.iterrows():\n",
        "        order_id = int(row[\"order_id\"])\n",
        "        user_history = history_orders[\n",
        "            (history_orders[\"user_id\"] == row[\"user_id\"])\n",
        "            & (history_orders[\"order_number\"] < row[\"order_number\"])\n",
        "        ].tail(max_prior_orders)\n",
        "\n",
        "        segments: list[str] = []\n",
        "        total_products = 0\n",
        "\n",
        "        for _, h in user_history.iterrows():\n",
        "            if total_products >= max_product_names:\n",
        "                break\n",
        "            oid = int(h[\"order_id\"])\n",
        "            order_products = []\n",
        "            for pid in order_to_products.get(oid, []):\n",
        "                if pid not in product_text_map:\n",
        "                    continue\n",
        "                if total_products >= max_product_names:\n",
        "                    break\n",
        "                name = product_text_map[pid].split(\"Product: \")[1].split(\".\")[0].strip()\n",
        "                order_products.append(name)\n",
        "                total_products += 1\n",
        "\n",
        "            if not order_products:\n",
        "                continue\n",
        "\n",
        "            dow = int(h[\"order_dow\"])\n",
        "            hour = (\n",
        "                h[\"order_hour_of_day\"]\n",
        "                if isinstance(h[\"order_hour_of_day\"], str)\n",
        "                else str(int(h[\"order_hour_of_day\"]))\n",
        "            )\n",
        "            if pd.isna(h[\"days_since_prior_order\"]):\n",
        "                time_prefix = f\"w{dow}h{hour}\"\n",
        "            else:\n",
        "                days_gap = int(h[\"days_since_prior_order\"])\n",
        "                time_prefix = f\"+{days_gap}d w{dow}h{hour}\"\n",
        "            seg = f\"[{time_prefix}] \" + \", \".join(order_products)\n",
        "            segments.append(seg)\n",
        "\n",
        "        products_str = \"; \".join(segments) if segments else \"(no prior orders)\"\n",
        "        row_dow = int(row[\"order_dow\"])\n",
        "        row_hour = (\n",
        "            row[\"order_hour_of_day\"]\n",
        "            if isinstance(row[\"order_hour_of_day\"], str)\n",
        "            else str(int(row[\"order_hour_of_day\"]))\n",
        "        )\n",
        "        if pd.isna(row[\"days_since_prior_order\"]):\n",
        "            next_clause = f\"Next: w{row_dow}h{row_hour}\"\n",
        "        else:\n",
        "            gap = int(row[\"days_since_prior_order\"])\n",
        "            next_clause = f\"Next: +{gap}d w{row_dow}h{row_hour}\"\n",
        "        context = f\"{products_str}. {next_clause}\"\n",
        "        order_id_to_context[order_id] = context\n",
        "\n",
        "    return order_id_to_context\n",
        "\n",
        "order_id_to_context = build_user_context_for_target_orders(\n",
        "    target_orders,\n",
        "    history_orders,\n",
        "    order_to_products,\n",
        "    product_text_map,\n",
        "    max_prior_orders=MAX_PRIOR_ORDERS,\n",
        "    max_product_names=MAX_PRODUCT_NAMES,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num train orders with context: 500\n",
            "\n",
            "Sample contexts (first 2):\n",
            "\n",
            "order_id 1187899.0:\n",
            "Previously ordered: [ordered on weekday 2 at hour 8.0] Soda, Organic Unsweetened Vanilla Almond Milk, Original Beef Jerky, Aged White Cheddar Popcorn, XL Pick-A-Size Paper Towel Rolls; [ordered 15 days after previous order on weekday 3 at hour 7.0] Soda, Pistachios, Original Beef Jerky, Bag of Organ...\n",
            "\n",
            "order_id 1492625.0:\n",
            "Previously ordered: [ordered on weekday 2 at hour 11.0] Chipotle Beef & Pork Realstick, Organic Avocado, Roasted Turkey, Baked Organic Sea Salt Crunchy Pea Snack, Thin Stackers Brown Rice Lightly Salted, Cheddar Bunnies Snack Crackers, Plantain Chips, Organic Just Concord Grape Juice, Uncured Genoa ...\n"
          ]
        }
      ],
      "source": [
        "print(\"Num train orders with context:\", len(order_id_to_context))\n",
        "print(\"\\nSample contexts (compact format, first 2):\")\n",
        "for oid, ctx in list(order_id_to_context.items())[:2]:\n",
        "    print(f\"\\norder_id {oid}:\")\n",
        "    print(ctx[:300] + \"...\" if len(ctx) > 300 else ctx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. `build_anchor_positive_pairs`\n",
        "\n",
        "Build (anchor, positive, order_id) from order_products__train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_anchor_positive_pairs(\n",
        "    order_products_train_path: Path,\n",
        "    order_id_to_context: dict[int, str],\n",
        "    product_text_map: dict[int, str],\n",
        ") -> tuple[list[str], list[str], list[int]]:\n",
        "    \"\"\"\n",
        "    Build (anchor, positive) training pairs from order_products__train.\n",
        "    Each row gives one positive pair; returns order_id per row for train/eval split.\n",
        "    \"\"\"\n",
        "    train_op = pd.read_csv(order_products_train_path)\n",
        "    anchors, positives, order_ids = [], [], []\n",
        "    for _, row in train_op.iterrows():\n",
        "        order_id = row[\"order_id\"]\n",
        "        product_id = row[\"product_id\"]\n",
        "        if order_id not in order_id_to_context or product_id not in product_text_map:\n",
        "            continue\n",
        "        anchors.append(order_id_to_context[order_id])\n",
        "        positives.append(product_text_map[product_id])\n",
        "        order_ids.append(order_id)\n",
        "    return anchors, positives, order_ids\n",
        "\n",
        "anchors, positives, order_ids = build_anchor_positive_pairs(\n",
        "    DATA_DIR / \"order_products__train.csv\",\n",
        "    order_id_to_context,\n",
        "    product_text_map,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total pairs (before split): 5163\n",
            "\n",
            "Sample pair 0:\n",
            "ANCHOR: Previously ordered: [7 days since prior, weekday 4, hour 12.0] Variety Pack Hard Cider, Instant Oatmeal Maple & Brown Sugar; [4 days since prior, weekday 1, hour 8.0] French Vanilla Coffee Creamer, Ha ...\n",
            "\n",
            "POSITIVE: Product: Natural Vanilla Ice Cream. Aisle: ice cream ice. Department: frozen.\n"
          ]
        }
      ],
      "source": [
        "print(\"Total pairs (before split):\", len(anchors))\n",
        "print(\"\\nSample pair 0:\")\n",
        "print(\"ANCHOR:\", anchors[0][:200], \"...\")\n",
        "print(\"\\nPOSITIVE:\", positives[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train / eval split and final datasets\n",
        "\n",
        "Split by order; optionally sample train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_order_ids_all = set(order_id_to_context.keys())\n",
        "order_list = sorted(train_order_ids_all)\n",
        "n_eval = max(1, int(len(order_list) * EVAL_FRAC))\n",
        "eval_order_ids = set(order_list[-n_eval:])\n",
        "\n",
        "train_anchors, train_positives = [], []\n",
        "eval_anchors, eval_positives = [], []\n",
        "for a, p, oid in zip(anchors, positives, order_ids):\n",
        "    if oid in eval_order_ids:\n",
        "        eval_anchors.append(a)\n",
        "        eval_positives.append(p)\n",
        "    else:\n",
        "        train_anchors.append(a)\n",
        "        train_positives.append(p)\n",
        "\n",
        "if SAMPLE_FRAC is not None and SAMPLE_FRAC < 1.0:\n",
        "    train_df = pd.DataFrame({\"anchor\": train_anchors, \"positive\": train_positives})\n",
        "    train_df = train_df.sample(frac=SAMPLE_FRAC, random_state=SEED)\n",
        "    train_anchors = train_df[\"anchor\"].tolist()\n",
        "    train_positives = train_df[\"positive\"].tolist()\n",
        "\n",
        "train_dataset = Dataset.from_dict({\"anchor\": train_anchors, \"positive\": train_positives})\n",
        "eval_dataset = Dataset.from_dict({\"anchor\": eval_anchors, \"positive\": eval_positives}) if eval_anchors else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train pairs: 4615\n",
            "Eval pairs: 548\n",
            "Eval orders: 50\n",
            "\n",
            "train_dataset: Dataset({\n",
            "    features: ['anchor', 'positive'],\n",
            "    num_rows: 4615\n",
            "})\n",
            "eval_dataset: Dataset({\n",
            "    features: ['anchor', 'positive'],\n",
            "    num_rows: 548\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(\"Train pairs:\", len(train_anchors))\n",
        "print(\"Eval pairs:\", len(eval_anchors))\n",
        "print(\"Eval orders:\", len(eval_order_ids))\n",
        "print(\"\\ntrain_dataset:\", train_dataset)\n",
        "if eval_dataset is not None:\n",
        "    print(\"eval_dataset:\", eval_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Eval information retrieval artifacts\n",
        "\n",
        "`eval_queries`, `eval_corpus`, `eval_relevant_docs` for InformationRetrievalEvaluator. When `EVAL_SERVE_TIME=True`, strip \" Next: ...\" from eval queries so eval matches production (script: `--no-eval-serve-time` to keep it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def strip_next_order_from_context(context: str) -> str:\n",
        "    \"\"\"Remove the ' Next: ...' clause for eval/serve (we don't know next order time at serve time).\"\"\"\n",
        "    if \" Next:\" in context:\n",
        "        return context.split(\" Next:\")[0].strip()\n",
        "    return context\n",
        "\n",
        "if EVAL_SERVE_TIME:\n",
        "    eval_queries = {\n",
        "        str(oid): strip_next_order_from_context(order_id_to_context[oid])\n",
        "        for oid in eval_order_ids\n",
        "        if oid in order_id_to_context\n",
        "    }\n",
        "else:\n",
        "    eval_queries = {\n",
        "        str(oid): order_id_to_context[oid]\n",
        "        for oid in eval_order_ids\n",
        "        if oid in order_id_to_context\n",
        "    }\n",
        "eval_relevant_docs = {str(oid): set() for oid in eval_order_ids}\n",
        "train_op = pd.read_csv(DATA_DIR / \"order_products__train.csv\")\n",
        "for _, row in train_op.iterrows():\n",
        "    oid = int(row[\"order_id\"])\n",
        "    oid_str = str(oid)\n",
        "    if oid_str in eval_relevant_docs:\n",
        "        eval_relevant_docs[oid_str].add(str(int(row[\"product_id\"])))\n",
        "eval_corpus = {str(pid): text for pid, text in product_text_map.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval_queries: 50\n",
            "eval_corpus (products): 49688\n",
            "eval_relevant_docs: 50\n",
            "\n",
            "Sample query (first qid):\n",
            "  qid=3105153.0\n",
            "  query: Previously ordered: [weekday 5, hour 8.0] Peppermint Mocha Liquid Coffee Creamer, Chicken & Apple Smoked Chicken Sausage, Chunky Medium Salsa, Organic ...\n",
            "  relevant_docs: []\n"
          ]
        }
      ],
      "source": [
        "print(\"eval_queries:\", len(eval_queries))\n",
        "print(\"eval_corpus (products):\", len(eval_corpus))\n",
        "print(\"eval_relevant_docs:\", len(eval_relevant_docs))\n",
        "print(\"\\nSample query (first qid):\")\n",
        "qid = list(eval_queries.keys())[0]\n",
        "print(f\"  qid={qid}\")\n",
        "print(\"  query:\", eval_queries[qid][:150], \"...\")\n",
        "print(\"  relevant_docs:\", list(eval_relevant_docs.get(qid, []))[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. (Optional) Save to disk\n",
        "\n",
        "Script writes to a param-based subdir under `OUTPUT_DIR` (e.g. `p5_mp20_ef0.1`) and saves `data_prep_params.json`. Uncomment to write."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import json\n",
        "#\n",
        "# def _params_subdir(max_prior_orders, max_product_names, eval_frac, eval_serve_time, sample_frac, max_target_orders):\n",
        "#     parts = [f\"p{max_prior_orders}\", f\"mp{max_product_names}\", f\"ef{eval_frac}\"]\n",
        "#     if not eval_serve_time:\n",
        "#         parts.append(\"no_serve\")\n",
        "#     if sample_frac is not None:\n",
        "#         parts.append(f\"sf{sample_frac}\")\n",
        "#     if max_target_orders is not None:\n",
        "#         parts.append(f\"mt{max_target_orders}\")\n",
        "#     return \"_\".join(parts)\n",
        "#\n",
        "# subdir = _params_subdir(MAX_PRIOR_ORDERS, MAX_PRODUCT_NAMES, EVAL_FRAC, EVAL_SERVE_TIME, SAMPLE_FRAC, MAX_TARGET_ORDERS)\n",
        "# effective_output_dir = OUTPUT_DIR / subdir\n",
        "# effective_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "#\n",
        "# train_dataset.save_to_disk(str(effective_output_dir / \"train_dataset\"))\n",
        "# if eval_dataset is not None:\n",
        "#     eval_dataset.save_to_disk(str(effective_output_dir / \"eval_dataset\"))\n",
        "# with open(effective_output_dir / \"eval_queries.json\", \"w\") as f:\n",
        "#     json.dump(eval_queries, f, indent=0)\n",
        "# with open(effective_output_dir / \"eval_corpus.json\", \"w\") as f:\n",
        "#     json.dump(eval_corpus, f, indent=0)\n",
        "# with open(effective_output_dir / \"eval_relevant_docs.json\", \"w\") as f:\n",
        "#     json.dump({k: list(v) for k, v in eval_relevant_docs.items()}, f, indent=0)\n",
        "# data_prep_params = {\"data_dir\": str(DATA_DIR), \"output_dir\": str(effective_output_dir), \"max_prior_orders\": MAX_PRIOR_ORDERS, \"max_product_names\": MAX_PRODUCT_NAMES, \"sample_frac\": SAMPLE_FRAC, \"eval_frac\": EVAL_FRAC, \"eval_serve_time\": EVAL_SERVE_TIME, \"max_target_orders\": MAX_TARGET_ORDERS, \"seed\": SEED, \"n_train_pairs\": len(train_anchors), \"n_eval_pairs\": len(eval_anchors), \"n_eval_queries\": len(eval_queries), \"n_corpus\": len(eval_corpus)}\n",
        "# with open(effective_output_dir / \"data_prep_params.json\", \"w\") as f:\n",
        "#     json.dump(data_prep_params, f, indent=2)\n",
        "# print(\"Saved to\", effective_output_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Instacart (uv .venv)",
      "language": "python",
      "name": "instacart-personalization"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
