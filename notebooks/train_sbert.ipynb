{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train two-tower SBERT on Instacart data\n",
        "\n",
        "This notebook mirrors `src/train` so you can run and inspect each step interactively.\n",
        "It assumes you have already run the data prep (`src.data.prepare_instacart_sbert`) and have\n",
        "datasets under `processed/`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup: imports and paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_ROOT: /Users/chen_bowen/AI & ML/Projects/Instacart_Personalization\n",
            "PROCESSED_DIR: /Users/chen_bowen/AI & ML/Projects/Instacart_Personalization/processed\n",
            "OUTPUT_DIR: /Users/chen_bowen/AI & ML/Projects/Instacart_Personalization/models/two_tower_sbert_notebook\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "from datasets import Dataset, load_from_disk\n",
        "from sentence_transformers import (\n",
        "    SentenceTransformer,\n",
        "    SentenceTransformerTrainer,\n",
        "    SentenceTransformerTrainingArguments,\n",
        ")\n",
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
        "from sentence_transformers.training_args import BatchSamplers\n",
        "\n",
        "# Project root (parent of notebooks/) if you start Jupyter from project root\n",
        "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
        "PROCESSED_DIR = PROJECT_ROOT / \"processed\"\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"models\" / \"two_tower_sbert_notebook\"\n",
        "\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n",
        "print(\"OUTPUT_DIR:\", OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load processed datasets and Information retrieval artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_dataset: Dataset({\n",
            "    features: ['anchor', 'positive'],\n",
            "    num_rows: 1246220\n",
            "})\n",
            "eval_dataset: Dataset({\n",
            "    features: ['anchor', 'positive'],\n",
            "    num_rows: 138397\n",
            "})\n",
            "#queries: 13120 #corpus docs: 49688 #qrels: 13120\n"
          ]
        }
      ],
      "source": [
        "train_dataset = load_from_disk(str(PROCESSED_DIR / \"train_dataset\"))\n",
        "eval_dataset = None\n",
        "if (PROCESSED_DIR / \"eval_dataset\").exists():\n",
        "    eval_dataset = load_from_disk(str(PROCESSED_DIR / \"eval_dataset\"))\n",
        "\n",
        "with open(PROCESSED_DIR / \"eval_queries.json\", \"r\") as f:\n",
        "    eval_queries = json.load(f)\n",
        "with open(PROCESSED_DIR / \"eval_corpus.json\", \"r\") as f:\n",
        "    eval_corpus = json.load(f)\n",
        "with open(PROCESSED_DIR / \"eval_relevant_docs.json\", \"r\") as f:\n",
        "    _raw = json.load(f)\n",
        "    eval_relevant_docs = {k: set(v) for k, v in _raw.items()}\n",
        "\n",
        "print(\"train_dataset:\", train_dataset)\n",
        "print(\"eval_dataset:\", eval_dataset)\n",
        "print(\"#queries:\", len(eval_queries), \"#corpus docs:\", len(eval_corpus), \"#qrels:\", len(eval_relevant_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect a sample pair and one Information retrieval example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anchor sample (user context):\n",
            " Previously ordered: Tuna Ventresca, in Olive Oil (x1), Bulgarian Yogurt (x2), Organic 4% Milk Fat Whole Milk Cottage Cheese (x2), Organic Small Bunch Celery (x2), Organic Whole String Cheese (x2), Banana (x1), Plus Cranberry Almond + Antioxidants with Macadamia Nuts Bar (x1), Pure Sparkling Water (x3), Dark Chocolate Cinnamon Pecan Bar (x2), Sparkling Water Grapefruit (x1), Naturally Smoked Oyster ...\n",
            "\n",
            "Positive sample (product):\n",
            " Product: Bulgarian Yogurt. Aisle: yogurt. Department: dairy eggs.\n",
            "\n",
            "Sample eval query id: 3178496\n",
            "Query text:\n",
            " Previously ordered: Organic Romaine Lettuce (x1), Organic Red Radish, Bunch (x1), Organic Rainbow Chard Vegetable (x1), Organic Dandelion Greens (x1), Chinese Eggplant (x1), Organic Zucchini (x1), Organic Grape Tomatoes (x1), Veggie Ground (x1), Mini Crispy Crabless Cakes (x1), Lemongrass Basil Simmer Sauce (x1), Orange Mango Chicken (x1), Golden Fishless Filet (x4), Chicken Drumsticks (x1), Organ ...\n",
            "\n",
            "Relevant product ids (first 10): ['31553', '41290', '13500', '5602', '31343']\n"
          ]
        }
      ],
      "source": [
        "sample = train_dataset[0]\n",
        "print(\"Anchor sample (user context):\\n\", sample[\"anchor\"][:400], \"...\\n\")\n",
        "print(\"Positive sample (product):\\n\", sample[\"positive\"])\n",
        "qid = list(eval_queries.keys())[0]\n",
        "print(\"\\nSample eval query id:\", qid)\n",
        "print(\"Query text:\\n\", eval_queries[qid][:400], \"...\\n\")\n",
        "print(\"Relevant product ids (first 10):\", list(eval_relevant_docs[qid])[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Build model and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41679280af5b4e818c1829dc384458dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(SentenceTransformer(\n",
              "   (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
              "   (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "   (2): Normalize()\n",
              " ),\n",
              " MultipleNegativesRankingLoss(\n",
              "   (model): SentenceTransformer(\n",
              "     (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
              "     (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "     (2): Normalize()\n",
              "   )\n",
              "   (cross_entropy_loss): CrossEntropyLoss()\n",
              " ))"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"  # change if you like\n",
        "MAX_SEQ_LENGTH = 256\n",
        "\n",
        "model = SentenceTransformer(MODEL_NAME)\n",
        "model.max_seq_length = MAX_SEQ_LENGTH\n",
        "\n",
        "loss = MultipleNegativesRankingLoss(model)\n",
        "model, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Build InformationRetrievalEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sentence_transformers.evaluation.InformationRetrievalEvaluator.InformationRetrievalEvaluator at 0x1284424e0>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "information_retrieval_evaluator = InformationRetrievalEvaluator(\n",
        "    queries=eval_queries,\n",
        "    corpus=eval_corpus,\n",
        "    relevant_docs=eval_relevant_docs,\n",
        "    name=\"instacart-two-tower-notebook\",\n",
        ")\n",
        "information_retrieval_evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Define training arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SentenceTransformerTrainingArguments(output_dir='/Users/chen_bowen/AI & ML/Projects/Instacart_Personalization/models/two_tower_sbert_notebook', do_train=False, do_eval=True, do_predict=False, eval_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=True, per_device_train_batch_size=32, per_device_eval_batch_size=32, gradient_accumulation_steps=1, eval_accumulation_steps=None, eval_delay=0, torch_empty_cache_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, lr_scheduler_kwargs=None, warmup_ratio=0.1, warmup_steps=0.1, log_level='passive', log_level_replica='warning', log_on_each_node=True, logging_dir=None, logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=100, logging_nan_inf_filter=True, save_strategy=<SaveStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=2, enable_jit_checkpoint=False, save_on_each_node=False, save_only_model=False, restore_callback_states_from_checkpoint=False, use_cpu=False, seed=42, data_seed=None, bf16=False, fp16=True, bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, ddp_backend=None, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, dataloader_prefetch_factor=None, run_name=None, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, fsdp=[], fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, accelerator_config=AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False), parallelism_config=None, deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_TORCH_FUSED: 'adamw_torch_fused'>, optim_args=None, group_by_length=False, length_column_name='length', report_to=[], project='huggingface', trackio_space_id='trackio', ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=False, dataloader_pin_memory=True, dataloader_persistent_workers=False, skip_memory_metrics=True, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=None, hub_always_push=False, hub_revision=None, gradient_checkpointing=False, gradient_checkpointing_kwargs=None, include_for_metrics=[], eval_do_concat_batches=True, auto_find_batch_size=False, full_determinism=False, ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, include_num_input_tokens_seen='no', neftune_noise_alpha=None, optim_target_modules=None, batch_eval_metrics=False, eval_on_start=False, use_liger_kernel=False, liger_kernel_config=None, eval_use_gather_object=False, average_tokens_across_devices=True, use_cache=False, prompts=None, batch_sampler=<BatchSamplers.NO_DUPLICATES: 'no_duplicates'>, multi_dataset_batch_sampler=<MultiDatasetBatchSamplers.PROPORTIONAL: 'proportional'>, router_mapping={}, learning_rate_mapping={})"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Performance optimizations:\n",
        "# - dataloader_num_workers=4: parallel data loading (was 0 = single-threaded bottleneck)\n",
        "# - dataloader_pin_memory=True: faster GPU transfer (if CUDA available)\n",
        "# - eval_steps: Information retrieval evaluator can be slow; increase to reduce frequency or disable with --no-information-retrieval-evaluator\n",
        "# - Consider increasing batch_size if GPU memory allows\n",
        "training_args = SentenceTransformerTrainingArguments(\n",
        "    output_dir=str(OUTPUT_DIR),\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=32,  # Increase if GPU memory allows (64, 128, etc.)\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    fp16=True,\n",
        "    batch_sampler=BatchSamplers.NO_DUPLICATES,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=1000,  # Increased from 500 - Information retrieval evaluation is expensive\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=100,\n",
        "    # Performance optimizations:\n",
        "    dataloader_num_workers=4,  # parallel data loading (was 0 = single-threaded bottleneck)\n",
        "    dataloader_pin_memory=True,  # faster GPU transfer (if CUDA available)\n",
        "    gradient_accumulation_steps=1,  # increase to 2-4 if you want larger effective batch size\n",
        ")\n",
        "training_args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Create trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ca8e06dce7343599d7f32c29a62db8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<sentence_transformers.trainer.SentenceTransformerTrainer at 0x10ad562d0>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note: Information retrieval evaluator can be slow. For faster training, set evaluator=None below.\n",
        "# You'll still get validation loss from eval_dataset, but won't see Recall@k/MRR metrics during training.\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    loss=loss,\n",
        "    evaluator=information_retrieval_evaluator,  # Set to None for faster training (only validation loss)\n",
        ")\n",
        "trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train (run a short experiment)\n",
        "\n",
        "You can run this cell to start training. For quick experiments, keep epochs small\n",
        "and optionally downsample `train_dataset` above. The Information retrieval evaluator\n",
        "will run periodically during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/chen_bowen/AI & ML/Projects/Instacart_Personalization/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
            "  super().__init__(loader)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='309' max='38945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  309/38945 02:03 < 4:19:30, 2.48 it/s, Epoch 0.01/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# This will start training and periodically run the Information retrieval evaluator.\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save final model (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_dir = OUTPUT_DIR / \"final_notebook\"\n",
        "final_dir.mkdir(parents=True, exist_ok=True)\n",
        "model.save_pretrained(str(final_dir))\n",
        "print(\"Saved model to\", final_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
